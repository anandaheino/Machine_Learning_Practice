{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's a classification technique based on the linear combination between X variables.\n",
    "- Also called _logit_.\n",
    "\n",
    "ex: $f(X) = \\alpha + b_1x_1 + b_2x_2 +\\dots + b_nx_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Function\n",
    "- Sigmoid is a special function used in logistic regression\n",
    "- Logistic regression's goal is to find $p($**x**$)$ which the **y** = $p(x_i)$ stay closest to the real values $y_i$ for each sample $i = 1, 2, \\dots, n$\n",
    "- Here, we are going to deal with binary classification (at the first moment)\n",
    "- The outputs should be only $0$ or $1$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear combination **x** Sigmoid function\n",
    "\n",
    "- Logistic regression determines the best values for bias $\\alpha$ and weights $b_1, b_2, \\dots, b_n$\n",
    "- The function $p($**x**$)$, then, should ne closer to the real value\n",
    "- _fitting_ is the optimization process to find the best hyerparameters\n",
    "\n",
    "In this case, the input **x** to the Sigmoid function ($p$) is the output from the linear combination $f(X) = \\alpha + b_1x_1 + b_2x_2 +\\dots + b_nx_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to tune the bias and the weights?\n",
    "\n",
    "- Max (_log-likelihood_ ) is used to find the best weights\n",
    "    - This method is called _maximum likelihood estimation_ - MLE which is represented by:\n",
    "\n",
    "\\begin{equation}\n",
    "MLE = \\sum_{i=1}^n(y_i log(p(x_i)) + (1 − y_i) log(1 − p(x_i))).\n",
    "\\end{equation}\n",
    "\n",
    "- `Scikit-learn` has great mathemathical ways to maximize the hyperparameters showed above:\n",
    "   - solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}, \n",
    "   - default='lbfgs'\n",
    "\n",
    "   - Algorithm to use in the optimization problem.\n",
    "\n",
    "       - For small datasets, 'liblinear' is a good choice, whereas 'sag' and 'saga' are faster for large ones.\n",
    "      - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs' handle multinomial loss; 'liblinear' is limited to one-versus-rest schemes.\n",
    "      - 'newton-cg', 'lbfgs', 'sag' and 'saga' handle L2 or no penalty\n",
    "      - 'liblinear' and 'saga' also handle L1 penalty\n",
    "      - 'saga' also supports 'elasticnet' penalty\n",
    "      - 'liblinear' does not support setting ``penalty='none'``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation:\n",
    "# 1) Binary classification with one input variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating random input values\n",
    "x = np.arange(10) \n",
    "print(x)\n",
    "x.shape      #Note the shape here, we need to reshape to use this array in the LogisticRegression instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "y = [0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape(-1, 1)       #after this reshaping we won't get any error message\n",
    "\n",
    "# Generating the classes [0, 1] for each sample\n",
    "y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "print(f'x = {x}')\n",
    "print(f'y = {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes = [0 1]\n",
      "bias = [-1.04608067]\n",
      "weights = [[0.51491375]]\n"
     ]
    }
   ],
   "source": [
    "# Instancing the model LogisticRegression\n",
    "\n",
    "# solver: used to optimize the parameters\n",
    "#    - liblinear: best option for SMALL and BINARY datasets.\n",
    "#    - random_state = x, no matter what number. Just to make sure it will always be the same result\n",
    "model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# Training the model with our data\n",
    "model.fit(x, y)\n",
    "\n",
    "# Extracting information from the model\n",
    "print(f'classes = {model.classes_}')\n",
    "print(f'bias = {model.intercept_}')\n",
    "print(f'weights = {model.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilities = \n",
      "[[0.74002157 0.25997843]\n",
      " [0.62975524 0.37024476]\n",
      " [0.5040632  0.4959368 ]\n",
      " [0.37785549 0.62214451]\n",
      " [0.26628093 0.73371907]\n",
      " [0.17821501 0.82178499]\n",
      " [0.11472079 0.88527921]\n",
      " [0.07186982 0.92813018]\n",
      " [0.04422513 0.95577487]\n",
      " [0.02690569 0.97309431]]\n",
      "\n",
      "estimated_class = \n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      "\n",
      "real_class = \n",
      " [0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "\n",
    "# Let's look at the probabilities of each class\n",
    "probabilities = model.predict_proba(x)\n",
    "estimated_class = model.predict(x)\n",
    "\n",
    "print(f'probabilities = \\n{probabilities}\\n')\n",
    "print(f'estimated_class = \\n {estimated_class}\\n')\n",
    "print(f'real_class = \\n {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we compare the probabilities with the predicted values..\n",
    "1) [0.74002157 - 0.259978 ] = [class 0 - class 1]   --->  class 0 has higher probability of beeing the right class\n",
    "3) [0.5040632 - 0.4959368 ]  = [class 0 - class 1]   --->  the values are really close.\n",
    "\n",
    "- so, we have a probabilty associated with the choice of the class, and depending on the matter of the problem, we may need that value to make confident decisions.\n",
    "\n",
    "#### Example: \n",
    "   - if we are predicting if the person has cancer, based on her exams, the doctor should say that the pacient is really with cancer if the chance is almost 50/50%? Well, maybe he will think about doing the exam again checking other indicators before saying that to the pacient.\n",
    "   - on the other hand, if the probability is 95% of the pacient having cancer, the doctor should be alert about it and make an investigation into the pacient's medical record to confirm it.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Having 10 samples, the model correctly predicted 9, so the accuracy is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy is another important metric to evaluate the model\n",
    "# - values are between 0 and 1, it's based on the ( correct answers / total )  \n",
    "\n",
    "print('Having 10 samples, the model correctly predicted 9, so the accuracy is:')\n",
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way of accessing the accuracy metric:\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, estimated_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "- With the confusion matrix we can retrieve more detailed information from the classification model\n",
    "- We look at the correct answers, using 4 new metrics:\n",
    "\n",
    "    - (True negatives - **TN**): (zeros) correctly estimated\n",
    "    - (True positives - **TP**): (1's) correctly estimated\n",
    "    - (False negatives - **FN**): (zeros) wrongly estimated\n",
    "    - (False positives - **FP**): (1's) wrongly estimated\n",
    "![confusion matrix](https://miro.medium.com/max/2102/1*fxiTNIgOyvAombPJx5KGeA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM = \n",
      "[[3 1]\n",
      " [0 6]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y, estimated_class)\n",
    "print('CM = ')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAESCAYAAABATza9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh30lEQVR4nO3de1xUZf4H8M8MMFwGBlBR5BKoyEVARa3AQlxNxRLNNXX1t66XzNglDS1jXV0rRc3W1Wr7Edom2s9baWq5eUtDQgUVE1JAQBTBADNQAbnJ8Pz+MGYdAQV5dBA/79frvPQ85znnfM8c5sOZ85xRhRBCgIiIWkRp6AKIiNoChikRkQQMUyIiCRimREQSMEyJiCRgmBIRScAwJSKSwNjQBRBQW1uL/Px8WFlZQaFQGLocIvqNEAKlpaVwcHCAUnn3a0+GaSuQn58PZ2dnQ5dBRI3Iy8uDk5PTXfswTFsBKysrAMCf1hyEytzSwNVQS814kr8Y24qyslIM6uehe4/eDcO0Faj7aK8yt4TKgmH6qLO00hi6BJKsKbffOABFRCQBw5SISAKGKRGRBAxTIiIJGKZERBIwTImIJGCYEhFJwDAlIpKAYUpEJAHDlIhIAoYpEZEEDFMiIgkYpkREEjBMiYgkYJgSEUnAMCUikoBhSkQkAcOUiEgChikRkQQMUyIiCRimREQSMEyJiCRgmBIRScAwJSKSgGFKRCQBw5SISAKGKRGRBAxTIiIJGKZERBIwTImIJGCYEhFJwDAlIpKAYUpEJAHDlIhIAoYpEZEEDFMiIgkYpkREEjBMiYgkYJgSEUnAMCUikoBhSkQkAcOUiEgChikRkQQMUyIiCRimREQSMEyJiCQwNnQB1LYlf7MOBWdPofhiJipKilFTXQULmw5w8H4SfqOmor2Lu6FLpCZK/ekUjv7wPU4nJ+H0qZO4XJgPAEj7uczAlbUODFN6oH7c/iluVlWgvYs72v0WnFfzziEz7hucO7IbwXM/hGu/gYYtkprkkw+W4/t9/zF0Ga0Ww5QeqOF//RfsunrDWGWq135m72b88GkkYj9ZiMlrvofSiD+KrV3vvk/Bw8sbPr36wqd3Xwzx74HqqipDl9Vq8CeYHqjOnn0abPcJnoDkXetRUpiH4rxsdHD1eMiVUXNND5tj6BJatVYxAJWTkwOFQoHk5GRDl0IPkdLIBABgZGxi4EqIWq5VhOm9rFu3DgqFotFp6tSpAIBDhw412qewsBAA8M477+jajIyM4OzsjBkzZqC4uLjefo8ePYrnn38etra2MDMzg6+vL1auXAmtVqvXLy4uDoMGDUK7du1gYWGB7t27Y/Lkyaiurn7wL84jKuPQN7iWfwHWnV1g3dnF0OUQtViLPuZXV1dDpVLJqqVR48ePR3BwcL32qKgoLF++HK+88opee0ZGBjQajV5bx44ddX/39vbGgQMHoNVqkZ6ejmnTpuH69ev44osvdH127NiBcePGYerUqYiNjYWNjQ0OHDiAt956CwkJCfjyyy+hUCiQlpaG4OBgzJw5Ex999BHMzc2RlZWFr776ql7oPs5O7VyL4rxzqKmqwNVL51Gcdw7qdh0xZPY/oDQyMnR5RC3WrDAdOHAgfHx8YGxsjA0bNsDX1xexsbE4c+YM5s6di/j4eKjVagwdOhSrVq1Chw4dAAB79+5FZGQkzpw5AyMjIwQEBODDDz9Et27dmrRfc3NzmJub67XFxcVh2bJl+OSTT9C/f3+9ZR07doSNjU3jB21sDHt7ewCAo6Mjxo4di5iYGN3yGzdu4JVXXsHIkSOxZs0aXfv06dPRqVMnjBw5El9++SXGjx+P/fv3w97eHu+//76uX7du3RoM/8dZXvIRXDqdqJu3snPA4JnL0LGbtwGrIpKn2R/z169fD5VKhSNHjiA6OhrXrl3DoEGD4Ofnh6SkJOzduxeXL1/GuHHjdOvcuHEDc+bMQVJSEg4ePAilUonRo0ejtrb2voq+ePEixo4di1dffRXTp0+/r23UycnJwb59+/SusPfv34+ioiK8+eab9fqHhITA3d0dmzdvBgDY29ujoKAAP/zwQ5P3WVVVhZKSEr2prRv5zmf4y1epePnzBLy4+HNYd3bBzoWTkbRttaFLI5Ki2R/zu3fvrncVFhkZCT8/PyxdulTXtnbtWjg7OyMzMxPu7u4YM2aM3jbWrl0LOzs7pKWlwcfHp1n7Ly8vx4svvghvb2988MEHDfZxcnLSm3dxcUFqaqpu/vTp07C0tIRWq0VlZSUAYOXKlbrlmZmZAAAvL68Gt+/p6anrM3bsWOzbtw9BQUGwt7eHv78/Bg8ejD/96U/1bjXUWbZsGd59992mHXAbY6rWwKFHX7ww/xNs/9v/4PiWf8G5d390cvM1dGlELdLsK9O+ffvqzaekpCA2NhaWlpa6ydPTEwCQnZ0NAMjKysKECRPQtWtXaDQauLq6AgByc3ObXfDLL7+Ma9euYevWrTA2bvh3QXx8PJKTk3XT7t279ZZ7eHggOTkZJ06cQEREBIYNG4aZM2fW244Q4p71GBkZISYmBpcuXcL7778PR0dHLF26FN7e3igoKGhwnXnz5uH69eu6KS8vrwlH3rYYGZvArX8wIAQunjhk6HKIWqzZYapWq/Xmy8rKEBISohdeycnJyMrKwoABAwDc+mhcXFyMTz/9FMeOHcOxY8cAoNmj3cuXL8euXbuwc+dO3f3YhnTp0gVubm66ycVFf7RYpVLBzc0NPj4+eO+992BkZKR3pejufuubOunp6Q1uPz09XdenjqOjIyZNmoSPP/4YqampqKysRHR0dIPrm5qaQqPR6E2PIzONLQCgouSqgSsharkWPxrVp08fpKamwtXVVS/A3NzcoFarUVRUhIyMDCxYsACDBw+Gl5cXrl5t/ptnz549mD9/PmJiYtCrV6+Wlq1nwYIFWLFiBfLzb33XeOjQoWjXrh3++c9/1uv7zTff6K60G2Nra4vOnTvjxo0bUutsa/JTTwAANPbOBq6EqOVaHKZhYWEoLi7GhAkTcOLECWRnZ2Pfvn2YOnUqtFotbG1t0b59e6xZswbnzp3D999/jzlzmvdNiqysLEycOBHTp09HYGAgCgsL9aY7nxH95Zdf6vW5efNmo9sPCAhAz549dfd91Wo1Vq9eja+//hozZszATz/9hJycHHz22WeYMmUKXnrpJd0A2+rVq/HnP/8Z+/fvR3Z2NlJTUxEREYHU1FSEhIQ089VsWwrO/ojcU/EQdww0amtu4qfdG5H5wy4Yq8zg9gyffKBHX4u/Turg4IAjR44gIiICQ4cORVVVFVxcXBAcHAylUgmFQoEtW7Zg1qxZ8PHxgYeHBz766CMMHDiwyfvYtGkTrl27htWrV2P16vqjv0FBQTh06JBu3sOj/lcTExIS4O/v3+g+Zs+ejSlTpiAiIgLOzs546aWXEBsbiyVLliAwMBCVlZXo3r075s+fj/DwcCgUCgDAU089hcOHDyM0NBT5+fmwtLSEt7c3du7ciaCgoCYfY1t0Pf8ivv/fBTDT2MKuaw+YWdmgsuQqinKzUH71CoxUphj02hJYdehs6FKpCeIO7MUnHyzXzd/87TbdH0b8Ttf25/AIBD33eP5yVIimjLLQA1VSUgJra2tM/79jUFlYGrocaUouX0Laga+Qn3YCJZcvobL0KpTGJtDYOcLR92n0fP5/2uS3n17zb3vHBAA7vtiA+XNC79pnycpojB7/x4dU0YNXVlqCpzwdcP369XuObTBMW4G2GqaPq7Yapo+j5oTpI/HdfCKi1o5hSkQkAcOUiEgChikRkQQMUyIiCRimREQSMEyJiCRgmBIRScAwJSKSgGFKRCQBw5SISAKGKRGRBAxTIiIJGKZERBIwTImIJGCYEhFJwDAlIpKAYUpEJAHDlIhIAoYpEZEEDFMiIgkYpkREEjBMiYgkYJgSEUnAMCUikoBhSkQkAcOUiEgChikRkQQMUyIiCRimREQSMEyJiCRgmBIRScAwJSKSgGFKRCQBw5SISAKGKRGRBAxTIiIJGKZERBIwTImIJGCYEhFJwDAlIpKAYUpEJAHDlIhIAoYpEZEEDFMiIgkYpkREEjBMiYgkYJgSEUnAMCUiksDY0AXQfy153hMajcbQZVAL2T75mqFLIEmEtrrJfXllSkQkAcOUiEgChikRkQQMUyIiCRimREQSMEyJiCRgmBIRScAwJSKSgGFKRCQBw5SISAKGKRGRBAxTIiIJGKZERBIwTImIJGCYEhFJwDAlIpKAYUpEJAHDlIhIAoYpEZEEDFMiIgkYpkREEjBMiYgkYJgSEUnAMCUikoBhSkQkAcOUiEgChikRkQQMUyIiCRimREQSMEyJiCRgmBIRScAwJSKSgGFKRCQBw5SISAKGKRGRBAxTIiIJGKZERBIwTImIJGCYEhFJwDAlIpKAYUpEJAHDlIhIAoYpEZEEDFMiIgkYpkREEjBMiYgkYJgSEUnAMCUiksDY0AVQ21dRUYF/LF+GrV9uQV5uLmzbtcPQocFY+O5iODo6Gro8aiZRU4Gayz+itiQHoroUUBpDobKC0tIJJo7PGLo8g+GVKT1QlZWVCB4yCMuWLEZZWRlGjBwFJydnfL4+BgFP+uHC+fOGLpGaobb8F1Slb4L2SjKgUEJp3QVKi04QNVXQXkkxdHkGxStTeqDeWxqJ48cS8bR/AP6zZz8sLS0BAB+uWom/vvUGXn1lGvYfPGTYIqlJRE0FqrN3AaIGJl2eh5F1F73ltTcuG6iy1oFXpvTAVFdXIzrqYwDABx/9ry5IAeD12XPg69sT8T/E4ceTJw1VIjVDTcFxQFsJY4f+9YIUAJTqTgaoqvVgmNIDk3D0CK5fv46u3bqht59fveWjx7wEANj97a6HXRo1k6itgfZqBqA0hlE7L0OX0yo9MmGak5MDhUKB5ORkQ5dCTfRTyq17aL39+jS4vK799OmfHlpNdH9E+S9A7U0ozO2gUBpDW3IRN38+jJt5caj5JQXi5g1Dl2hwj0yYNlVqairGjRsHOzs7mJqawt3dHQsXLkR5ebleP1dXVygUCiQmJuq1h4eHY+DAgbr5d955BwqFot7k6emp63PhwgVMnDgRDg4OMDMzg5OTE0aNGoWzZ88+0GNt7fLycgEAjo5ODS6va8+7ePGh1UT3p7ayGACgMDZH9fnduHn+P9BeSYG26Axq8g+jKm0DtFczDVylYT3wAajq6mqoVKoHvRsAQGJiIp577jk899xz+Pbbb9GpUyccP34cb7zxBg4ePIjY2Fi9WszMzBAREYG4uLi7btfb2xsHDhzQazM2vvXS3bx5E0OGDIGHhwe2b9+Ozp0749KlS9izZw+uXbsm/RgfJTfKygAAFhYWDS5Xq9UAgNKy0odWE90nbRUAoPZ6DqBQwNhpAIxs3IDam6i5chraK8m4mXsQClNbKC3sDFurgUi/Mh04cCBee+01hIeHo0OHDhg2bBgA4MyZMxg+fDgsLS3RqVMnTJo0Cb/++qtuvb179+LZZ5+FjY0N2rdvjxEjRiA7O7vJ+xVC4OWXX4aXlxe2b9+Op556Ci4uLhg7dix27dqFhIQErFq1Sm+dGTNmIDExEbt3777rto2NjWFvb683dejQAcCtK+Hs7GxERUXB398fLi4ueOaZZxAZGQl/f/8m10/Uuonf/qyFsf1TMO7gC4WxORQqDUwcn4HSphsgalFz5ZRBqzSkB/Ixf/369VCpVDhy5Aiio6Nx7do1DBo0CH5+fkhKSsLevXtx+fJljBs3TrfOjRs3MGfOHCQlJeHgwYNQKpUYPXo0amtrm7TP5ORkpKWlYc6cOVAq9Q+rV69eeO6557B582a99i5duiA0NBTz5s1r8n7uZGdnB6VSiW3btkGr1TZpnaqqKpSUlOhNbZH6t9H7O2+x1Llx49Z9NitLq4dWE90npYnur0bt6w9A1Q1K1ZblP7SSWpsHEqbdu3fH+++/Dw8PD3h4eODjjz+Gn58fli5dCk9PT/j5+WHt2rWIjY1FZuat+yxjxozB73//e7i5uaF3795Yu3YtTp8+jbS0tCbts247Xl4NjzR6eXnp+txuwYIFuHDhAjZu3Njotk+fPg1LS0u9KTQ0FADg6OiIjz76CAsXLoStrS0GDRqExYsX4/xdHkZftmwZrK2tdZOzs3OTjvFR4+z8BADg558vNbi8rt3ZxeWh1UT3R6H67Ree0hgKY/PGl9dUPMSqWpcHEqZ9+/bVm09JSUFsbKxeGNUN4NR9lM/KysKECRPQtWtXaDQauLq6AgByc3ObtW8hxL073cbOzg5vvvkmFi5ciOrq6gb7eHh4IDk5WW9atGiRbnlYWBgKCwuxceNGBAQEYOvWrfD29sZ3333X4PbmzZuH69ev66a8vLxm1fyo6NmrFwAg+dSPDS6va/f17fnQaqL7ozT/7T5obQ1EbQOfwGqqfutoUn/ZY+KBDEDVDSzUKSsrQ0hICJYvX16vb+fOnQEAISEhcHFxwaeffgoHBwfU1tbCx8en0YC7k7u7OwAgPT0dfg0805ienq7rc6c5c+YgKioKUVFRDS5XqVRwc3O76/6trKwQEhKCkJAQREZGYtiwYYiMjMSQIUPq9TU1NYWpqem9DumRF9D/GVhbW+N8djZSkpPRq3dvveU7vtoGAHj+hRADVEfNoVBZQWHWHqKyCLVlP8NI84Te8tobPwMAlOYdDFFeq/BQHo3q06cPUlNT4erqCjc3N71JrVajqKgIGRkZWLBgAQYPHgwvLy9cvXq1Wfvo3bs3PD09sWrVqnr3P1NSUnDgwAFMmDChwXUtLS3x97//HUuWLEFpactHlusenaq7J/i4UqlUCP3LawCA8Flheq/Hh6tW4vTpnxA4IAh97vgkQ62TcadbzwXX5B/Ve660tvwKan5JBgAYdfAxRGmtwkMJ07CwMBQXF2PChAk4ceIEsrOzsW/fPkydOhVarRa2trZo37491qxZg3PnzuH777/HnDlzmrUPhUKBzz77DGlpaRgzZgyOHz+O3NxcbN26FSEhIQgICEB4eHij68+YMQPW1tbYtGlTvWU1NTUoLCzUmy5fvvU95OTkZIwaNQrbtm1DWloazp07h88++wxr167FqFGjmnUMbdFf/7YATz71NBITjsLHqzv+OHE8Bjzjj7++9Qbs7Oyw+tO1hi6RmsjI1h1KW0+IyiJUnd2M6vP/QfW5najO+grQVsGofY9bj0s9ph5KmDo4OODIkSPQarUYOnQofH19ER4eDhsbGyiVSiiVSmzZsgUnT56Ej48PZs+ejX/84x/N3k///v2RmJgIIyMjDB8+HG5ubpg3bx4mT56M77777q4frU1MTLB48WJUVlbWW5aamorOnTvrTS6/DZo4OTnB1dUV7777Lp5++mn06dMHH374Id59913Mnz+/2cfQ1piZmWHfgVjMm/93WFhYYNfXO5GXexGT/jQFR4//iC5duxq6RGoGkycGwdh5IBQqDWrLfkZt+WUozO1g8sRgmDj/ztDlGZRCNHfEhqQrKSmBtbU1Lhddh0ajMXQ51EK2T75m6BJIEqGtRtXpT3H9+r3fm23u66RERIbAMCUikoBhSkQkAcOUiEgChikRkQQMUyIiCRimREQSMEyJiCRgmBIRScAwJSKSgGFKRCQBw5SISAKGKRGRBAxTIiIJGKZERBIwTImIJGCYEhFJwDAlIpKAYUpEJAHDlIhIAoYpEZEEDFMiIgkYpkREEjBMiYgkYJgSEUnAMCUikoBhSkQkAcOUiEgChikRkQQMUyIiCRimREQSMEyJiCRgmBIRScAwJSKSgGFKRCQBw5SISAKGKRGRBAxTIiIJGKZERBIwTImIJGCYEhFJwDAlIpKAYUpEJAHDlIhIAoYpEZEEDFMiIgkYpkREEjBMiYgkYJgSEUlgbOgCCBBCAABKS0oMXAnJILTVhi6BJKk7l3Xv0bthmLYCpaWlAAC3Ls4GroSIGlJaWgpra+u79lGIpkQuPVC1tbXIz8+HlZUVFAqFoct5YEpKSuDs7Iy8vDxoNBpDl0Mt8LicSyEESktL4eDgAKXy7ndFeWXaCiiVSjg5ORm6jIdGo9G06Tfg4+RxOJf3uiKtwwEoIiIJGKZERBIwTOmhMTU1xdtvvw1TU1NDl0ItxHNZHwegiIgk4JUpEZEEDFMiIgkYpkREEjBMiYgkYJhSo1xdXfHBBx/o5hUKBXbu3Gmwekgenlv5GKbUZAUFBRg+fHiT+r7zzjvo3bv3Xfvk5ORAoVA0OnXp0kXXt7E+W7ZsAQAcOnRIr93Ozg7PP/88Tp8+XW+/eXl5mDZtGhwcHKBSqeDi4oLXX38dRUVFev0uXLiAiRMnwsHBAWZmZnBycsKoUaNw9uzZJr0GjxLZ57ZOcXExwsPD4eLiApVKBQcHB0ybNg25ubl6/aZMmQKFQoH33ntPr33nzp16X7G+8zzfPhUWFgIAysvLMW/ePHTr1g1mZmaws7NDUFAQvv766ybVfL/4ddI2rrq6GiqVSsq27O3tpWynjrOzMwoKCuq1JyUl4cUXX0RYWJhee0xMDIKDg/XabGxs9OYzMjKg0WiQn5+PuXPn4oUXXsC5c+d0r8H58+cREBAAd3d3bN68GV26dEFqairmzp2LPXv2IDExEe3atcPNmzcxZMgQeHh4YPv27ejcuTMuXbqEPXv24Nq1a1Jfh/vVms8tcCtI/f39oVKpEB0dDW9vb+Tk5GDBggV48sknkZCQgK5du+r6m5mZYfny5Xj11Vdha2t7123XnefbdezYEQAQGhqKY8eO4V//+hd69OiBoqIiHD16tN4vS+kEPTKCgoJEWFiYCAsLExqNRrRv314sWLBA1NbW6vq4uLiIRYsWiUmTJgkrKysxefJkIYQQ8fHx4tlnnxVmZmbCyclJzJw5U5SVlenWu3z5shgxYoQwMzMTrq6uYsOGDcLFxUWsWrVK1weA2LFjh24+Ly9P/OEPfxC2trbCwsJC9O3bVyQmJoqYmBgBQG+KiYlp0jEWFhYKJycn8cc//lGv/c593yk2NlYAEFevXtW1ffPNNwKASElJ0bUFBwcLJycnUV5errd+QUGBsLCwEKGhoUIIIU6dOiUAiJycnCbV3VJt8dyGhoYKtVotCgoK9NrLy8uFo6OjCA4O1rVNnjxZjBgxQnh6eoq5c+fq2nfs2CFuj6mGzvOdrK2txbp16xpd/qAwTB8hQUFBwtLSUrz++uvi7NmzYsOGDcLCwkKsWbNG18fFxUVoNBqxYsUKce7cOd2kVqvFqlWrRGZmpjhy5Ijw8/MTU6ZM0a03fPhw0atXL5GQkCCSkpJE//79hbm5eaNvuNLSUtG1a1cRGBgo4uPjRVZWlvjiiy/E0aNHRXl5uXjjjTeEt7e3KCgoEAUFBfXCqyHV1dXimWeeEf369RMVFRV6y5obpteuXRMTJ04UAER6eroQQoiioiKhUCjE0qVLG9zGK6+8ImxtbUVtba24dOmSUCqVYsWKFaKmpuaetbdUWzu3Wq1W2NjYiBkzZjR4vEuWLBEKhUIUFRUJIW6F6ahRo8T27duFmZmZyMvLE0LcX5h6eHiIcePGiZKSknu+7jIxTB8hQUFBwsvLS+9qJSIiQnh5eenmXVxcxIsvvqi33ssvv1zvhzo+Pl4olUpRUVEhMjIyBABx/Phx3fL09HQBoNE33OrVq4WVlZXuzXCnt99+W/Tq1atZxzdjxgxhb2+veyPdDoAwMzMTarVab7p48aIQ4r9vsrr2uqumkSNH6raRmJh411BeuXKlACAuX74shBDi448/FhYWFsLKykr87ne/E4sWLRLZ2dnNOqamamvntrCwsN4+brd9+3YBQBw7dkwI8d8wFUIIf39/MW3aNCFE42F6589Bjx49dH3i4uKEk5OTMDExEf369RPh4eHi8OHDd61XBg5APWL8/f31bsgHBAQgKysLWq1W19avXz+9dVJSUrBu3TpYWlrqpmHDhqG2thYXLlxAeno6jI2N0bdvX906np6e9e5H3i45ORl+fn5o166dlOOKjo7GunXr8NVXXzX6zxGuWrUKycnJepODg4Nen/j4eJw8eRLr1q2Du7s7oqOj621HNPEb1GFhYSgsLMTGjRsREBCArVu3wtvbG999913zD7AJ2uK5beprfbvly5dj/fr1SE9Pb7RPfHy83s/B7t27dcsGDBiA8+fP4+DBg3jppZeQmpqKwMBALF68+L6Ooak4ANUGqdVqvfmysjK8+uqrmDVrVr2+TzzxBDIzM5u9D3Nz8/uu706HDx/GrFmzEBUVhf79+zfaz97eHm5ubnfdVpcuXWBjYwMPDw/88ssvGD9+PH744QcAgJubGxQKBdLT0zF69Oh666anp8PW1hZ2dna6NisrK4SEhCAkJASRkZEYNmwYIiMjMWTIkPs82pZ5VM6tnZ0dbGxsGg3E9PR0KBSKBs/ngAEDMGzYMMybNw9TpkxpcP2689wYExMTBAYGIjAwEBEREYiMjMSiRYsQEREhbdDuTrwyfcQcO3ZMbz4xMRHdu3eHkZFRo+v06dMHaWlpcHNzqzepVCp4enqipqYGJ0+e1K2TkZFx11Hrnj17Ijk5GcXFxQ0uV6lUeldUjcnLy8OYMWMwY8YMTJ8+/Z79myMsLAxnzpzBjh07AADt27fHkCFDEBUVhYqKCr2+dVeg48ePb/R/O1AoFPD09MSNGzek1lmnLZ1bpVKJcePGYdOmTbpHlupUVFQgKioKw4YNa/Tq97333sOuXbuQkJBw1/00VY8ePVBTU4PKykop22vQA7+RQNLUDVLMnj1bnD17VmzatEmo1WoRHR2t63PnKK0QQqSkpAhzc3MRFhYmTp06JTIzM8XOnTtFWFiYrk9wcLDw8/MTiYmJIikpSTz77LN3HaSoqqoS7u7uIjAwUBw+fFhkZ2eLbdu2iaNHjwohhNi4caNQq9Xi1KlT4sqVK6KysrLe8VRUVIi+ffsKPz8/kZeXpxvQuH26fd8xMTH1lteNWjc2MPHWW28JX19f3b3IzMxM0aFDBxEYGCji4uJEbm6u2LNnj/Dx8RHdu3fX3Sc8deqUGDlypNi6datITU0VWVlZ4t///rdQq9Vi0aJFzTtxTdDWzq0QQvz666+iW7duwsfHR+zevVvk5uaKuLg4ERgYKDp27Kh3//n2e6Z1Jk2aJMzMzBq8Z5qRkVHvZ6G6ulr3WkZHR4ukpCRx4cIF8e233woPDw8xaNCgJp+P+8EwfYQEBQWJv/zlLyI0NFRoNBpha2sr/va3v9V7fKahm/7Hjx8XQ4YMEZaWlkKtVouePXuKJUuW6JYXFBSIF154QZiamoonnnhCfP755/d8fCYnJ0eMGTNGaDQaYWFhIfr166cbUKisrBRjxowRNjY2jT4+c+jQoXqP2dw53b7vhqZly5YJIRoP09zcXGFsbCy++OILvbonT54sOnXqJExMTISzs7OYOXOm+PXXX3V9rly5ImbNmiV8fHyEpaWlsLKyEr6+vmLFihVCq9Xe9Tzdj7Z2butcuXJFzJw5Uzg7OwsTExPRqVMnMWXKFN3AYZ2GwvTChQtCpVI1GKYNTQkJCUIIIZYuXSoCAgJEu3bthJmZmejatauYNWuW3vl9EPjvmT5CBg4ciN69e+t9DZDaBp7bRx/vmRIRScAwJSKSgB/ziYgk4JUpEZEEDFMiIgkYpkREEjBMiYgkYJgSEUnAMCUikoBhSkQkAcOUiEiC/wdN7dybLw632QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.imshow(cm, cmap=plt.cm.Blues)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('predict ZEROS', 'predict ONES'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('real ZEROS', 'real ONES'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center',  size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.93      0.88      0.89        10\n",
      "weighted avg       0.91      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting a detailed report from the classification\n",
    "print(classification_report(y, estimated_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Precision** = TP/TP+FP or TN/TN+FN\n",
    "- **Recall** = TP/TP+FN or TN/TN+FP\n",
    "- **support** -> number of samples\n",
    "- **F1-score, Macro AVG e Weighted AVG** -> similar o accuracy, but with weights\n",
    "\n",
    "# Optimizing the model\n",
    " - changing hyperparameters\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias =  [-3.51335372] \n",
      "\n",
      "weights =  [[1.12066084]] \n",
      "\n",
      "probabilities = \n",
      "\u001b[31m [[0.97106534 0.02893466]\n",
      " [0.9162684  0.0837316 ]\n",
      " [0.7810904  0.2189096 ]\n",
      " [0.53777071 0.46222929]\n",
      " [0.27502212 0.72497788]\n",
      " [0.11007743 0.88992257]\n",
      " [0.03876835 0.96123165]\n",
      " [0.01298011 0.98701989]\n",
      " [0.0042697  0.9957303 ]\n",
      " [0.00139621 0.99860379]] \u001b[m\n",
      "\n",
      "Estimated classes = \u001b[31m [0 0 0 0 1 1 1 1 1 1] \u001b[m\n",
      "\n",
      "Real classes =      \u001b[32m [0 0 0 0 1 1 1 1 1 1] \u001b[m\n"
     ]
    }
   ],
   "source": [
    "# increasing c, a regularization parameter \n",
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0).fit(x, y)\n",
    "\n",
    "print('bias = ',model.intercept_, '\\n')\n",
    "print('weights = ',model.coef_, '\\n')\n",
    "print('probabilities = \\n\\033[31m',model.predict_proba(x), '\\033[m\\n')\n",
    "print('Estimated classes = \\033[31m',model.predict(x), '\\033[m\\n')\n",
    "print('Real classes =      \\033[32m',y, '\\033[m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  1.0\n",
      "\n",
      "Confusion matrix = \n",
      "[[4 0]\n",
      " [0 6]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy = ', model.score(x, y))\n",
    "print('\\nConfusion matrix = ')\n",
    "print( confusion_matrix(y, model.predict(x)))\n",
    "print('\\nClassification Report:\\n', classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Changing the output class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing only the second class of y\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Passo 3: Criando e treinando o modelo\n",
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(x, y)\n",
    "\n",
    "# Passo 4: avaliando o modelo\n",
    "p_pred = model.predict_proba(x)\n",
    "y_pred = model.predict(x)\n",
    "score_ = model.score(x, y)\n",
    "conf_m = confusion_matrix(y, y_pred)\n",
    "report = classification_report(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias: [-1.51632619]\n",
      "weights: [[0.703457]]\n",
      "\n",
      "probabilities:\u001b[31m\n",
      "[[0.81999686 0.18000314]\n",
      " [0.69272057 0.30727943]\n",
      " [0.52732579 0.47267421]\n",
      " [0.35570732 0.64429268]\n",
      " [0.21458576 0.78541424]\n",
      " [0.11910229 0.88089771]\n",
      " [0.06271329 0.93728671]\n",
      " [0.03205032 0.96794968]\n",
      " [0.0161218  0.9838782 ]\n",
      " [0.00804372 0.99195628]]\n",
      "\n",
      "\u001b[mestimated classes:\u001b[31m [0 0 0 1 1 1 1 1 1 1]\n",
      "\n",
      "\u001b[mreal classes:     \u001b[32m [0 1 0 0 1 1 1 1 1 1]\n",
      "\n",
      "\u001b[maccuracy: 0.8\n",
      "\n",
      "confusion matrix:\n",
      "[[2 1]\n",
      " [1 6]]\n",
      "\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.76      0.76      0.76        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('bias:', model.intercept_)\n",
    "print('weights:', model.coef_, end='\\n\\n')\n",
    "print('probabilities:\\033[31m', p_pred, sep='\\n', end='\\n\\n')\n",
    "print('\\033[mestimated classes:\\033[31m', y_pred, end='\\n\\n')\n",
    "print('\\033[mreal classes:     \\033[32m', y, end='\\n\\n')\n",
    "print('\\033[maccuracy:', score_, end='\\n\\n')\n",
    "print('confusion matrix:', conf_m, sep='\\n', end='\\n\\n')\n",
    "print('Report:', report, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression doesn't solve non-linear problems\n",
    "- That means the model couldn't find a line to separate the classes\n",
    "- the accuracy will never be 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
