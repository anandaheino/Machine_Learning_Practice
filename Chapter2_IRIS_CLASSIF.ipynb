{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ref Book: \n",
    "\n",
    "Hands-On Machine Learning with scikit-learn and Scientific Python Toolkits: A practical guide to implementing supervised and unsupervised machine learning algorithms in Python\n",
    "\n",
    "Tarek Amr - 2020\n",
    "\n",
    "## Chapter 2 - Iris Dataset (Scikit-learn)\n",
    " - Classification problem\n",
    " - Three species are covered: Setosa, Versicolor, and Virginica. \n",
    " - FEATURES: length and the widths of the sepal and petal of each plant \n",
    " - TARGET: Setosa, a Versicolor, or a Virginica \n",
    " \n",
    "Our task is to be able to identify the species of a plant given its sepal and petal dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Instance the Iris dataset into iris variable\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'filename', 'target', 'target_names']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using dir , we can see what methods and attributes the dataset provides:\n",
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This description holds some useful information:\n",
    "- The data is composed of 150 rows (or 150 samples)... small dataset\n",
    "- We have to think on how to deal with this fact when evaluating our model.\n",
    "- Some classification algorithms can only deal with two class labels; we call them binary classifiers. \n",
    "- But the decision tree algorithm can deal with more than two classes, so we have no problems this time.\n",
    "- The data is balanced; there are 50 samples for each class. \n",
    "- There is four numeric features: sepal length , sepal width , petal length , and petal width\n",
    "- There are no missing attribute values.\n",
    "- The petal dimensions correlate with the class values more than the sepal dimensions... Understanding the data is useful, but the problem here is that this correlation is calculated for the entire dataset. Ideally, we will only calculate it for our training data. Anyway, let's IGNORE this information for now and just use it for a sanity check later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nome das classes:\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the Data into a DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = pd.Series(iris.target)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can see that the TARGET column has de class IDs\n",
    " - For more clarity, we can also create a new column called target_names , where we can map our numerical target values to the class names:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "73                 6.1               2.8                4.7               1.2   \n",
       "18                 5.7               3.8                1.7               0.3   \n",
       "118                7.7               2.6                6.9               2.3   \n",
       "78                 6.0               2.9                4.5               1.5   \n",
       "76                 6.8               2.8                4.8               1.4   \n",
       "31                 5.4               3.4                1.5               0.4   \n",
       "\n",
       "     target target_names  \n",
       "73        1   versicolor  \n",
       "18        0       setosa  \n",
       "118       2    virginica  \n",
       "78        1   versicolor  \n",
       "76        1   versicolor  \n",
       "31        0       setosa  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target_names'] = df['target'].apply(lambda y: iris.target_names[y])\n",
    "\n",
    "# A random sample from the dataframe: 6 rows, and we use random_state with the same \n",
    "# seed to produce equal results, everytime \n",
    "df.sample(n=6, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data\n",
    "Let's split the DataFrame into 2: \n",
    "- 70% of the records goes into the training set\n",
    "- 30% goes into testing set\n",
    "- choice of 70/30 is arbitrary\n",
    "\n",
    "We will use the `train_test_split()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº Rows in TEST:   45\n",
      "Nº Rows in TRAIN: 105\n"
     ]
    }
   ],
   "source": [
    "# checking how many rows in the test and train DataFrames\n",
    "print('Nº Rows in TEST:  ', df_test.shape[0])\n",
    "print('Nº Rows in TRAIN:', df_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature_names method in iris contains a list of the corresponding column names to our features. \n",
    "## Creating our `x` and `y` sets, as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train[iris.feature_names]\n",
    "x_test = df_test[iris.feature_names]\n",
    "\n",
    "y_train = df_train['target']\n",
    "y_test = df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "32                 5.2               4.1                1.5               0.1\n",
       "94                 5.6               2.7                4.2               1.3\n",
       "112                6.8               3.0                5.5               2.1\n",
       "56                 6.3               3.3                4.7               1.6\n",
       "11                 4.8               3.4                1.6               0.2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32     0\n",
       "94     1\n",
       "112    2\n",
       "56     1\n",
       "11     0\n",
       "      ..\n",
       "73     1\n",
       "119    2\n",
       "92     1\n",
       "143    2\n",
       "130    2\n",
       "Name: target, Length: 105, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model DecisionTreeClassifier and using it for prediction\n",
    "\n",
    "To get a feel for how everything works, we will train our algorithm using its default\n",
    "configuration for now. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# It is common to call the classifier instance clf\n",
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model using fit()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the fit() method, the clf instance is trained and ready to be used for\n",
    "#predictions, so we call the predict() method on x_test\n",
    "\n",
    "y_test_predicted = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our predictions\n",
    "As we have `y_test_predict` , all we need now is to compare it to `y_test` to check how\n",
    "good our predictions are. \n",
    "\n",
    "- Metrics for evaluating a classifier: precision , recall , and accuracy . \n",
    "\n",
    "The Iris dataset is a balanced dataset; it has the same number of instances for each class. Therefore, it is apt to use the accuracy metric here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_predicted)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "0.928343949044586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Erro quadrático RSS\n",
    "def calc_rss(y,predicted):\n",
    "    return float(((predicted - y) ** 2).sum())\n",
    "\n",
    "rss = calc_rss(y_test, y_test_predicted)\n",
    "print(rss)\n",
    "\n",
    "# ajuste R² \n",
    "r2 = r2_score(y_test, y_test_predicted)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which features were more important?\n",
    "We may now ask ourselves, Which features did the model find more useful in deciding the iris species? Luckily, DecisionTreeClassifier has a method called `feature_importances_` , which is computed after the classifier is fitted and scores how important each feature is to the model's decision. In the following code snippet, we will create a DataFrames where we will put the features' names and their importance together and then sort the features by their importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importances</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_names</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>petal width (cm)</th>\n",
       "      <td>0.559180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal length (cm)</th>\n",
       "      <td>0.411264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <td>0.015255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <td>0.014301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature_importances\n",
       "feature_names                         \n",
       "petal width (cm)              0.559180\n",
       "petal length (cm)             0.411264\n",
       "sepal length (cm)             0.015255\n",
       "sepal width (cm)              0.014301"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importances = pd.DataFrame(\n",
    "    {\n",
    "    'feature_names': iris.feature_names,  \n",
    "     'feature_importances': clf.feature_importances_\n",
    "    }\n",
    ").sort_values('feature_importances', ascending=False).set_index('feature_names')\n",
    "\n",
    "df_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the internal tree decisions\n",
    "We can also print the internal structure of the learned tree using the following code\n",
    "snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- petal width (cm) <= 0.8\n",
      "|   |--- class: 0\n",
      "|--- petal width (cm) >  0.8\n",
      "|   |--- petal length (cm) <= 4.8\n",
      "|   |   |--- class: 1\n",
      "|   |--- petal length (cm) >  4.8\n",
      "|   |   |--- petal width (cm) <= 1.8\n",
      "|   |   |   |--- petal length (cm) <= 5.3\n",
      "|   |   |   |   |--- sepal length (cm) <= 6.5\n",
      "|   |   |   |   |   |--- petal width (cm) <= 1.6\n",
      "|   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- petal width (cm) >  1.6\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- sepal length (cm) >  6.5\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- petal length (cm) >  5.3\n",
      "|   |   |   |   |--- class: 2\n",
      "|   |   |--- petal width (cm) >  1.8\n",
      "|   |   |   |--- petal length (cm) <= 4.9\n",
      "|   |   |   |   |--- sepal width (cm) <= 3.1\n",
      "|   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |--- sepal width (cm) >  3.1\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- petal length (cm) >  4.9\n",
      "|   |   |   |   |--- class: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "print(export_text(clf, feature_names=iris.feature_names, spacing=3, decimals=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you print the complete dataset description, you will notice that toward the end, it says\n",
    "the following:\n",
    "\n",
    "One class is linearly separable from the other two; the latter are NOT linearly separable\n",
    "from each other.\n",
    "\n",
    "This means that one class is easier to separate from the other two, while the other two are\n",
    "harder to separate from each other. Now, look at the internal tree's structure. You may\n",
    "notice that in the first step, it decided that anything with a petal width below or equal t\n",
    "0.8 belongs to class 0 ( Setosa ). Then, for petal widths above 0.8 , the tree kept on\n",
    "branching, trying to differentiate between classes 1 and 2 ( Versicolor and Virginica ).\n",
    "Generally, the harder it is to separate classes, the deeper the branching goes.\n",
    "\n",
    "# Checking overfitting by comparing:\n",
    "the classifier's accuracy on the test set to its accuracy on the training set. Having a much\n",
    "higher score for your training set compared to the test set is a sign of\n",
    "overfitting.\n",
    "\n",
    "https://machinelearningmastery.com/overfitting-machine-learning-models/\n",
    "\n",
    "We care about overfitting because it is a common cause for “poor generalization” of the model as measured by high “generalization error.” That is error made by the model when making predictions on new data.\n",
    "\n",
    "This means, if our model has poor performance, maybe it is because it has overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With no MAX_DEPTH() defined, our comparison of TEST and TRAIN is:\n",
      "\n",
      "0.9555555555555556\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Comparing test and train accuracy\n",
    "accuracy_test = accuracy_score(y_test, y_test_predicted)\n",
    "\n",
    "y_train_predicted = clf.predict(x_train)\n",
    "accuracy_train = accuracy_score(y_train, y_train_predicted)\n",
    "print('With no MAX_DEPTH() defined, our comparison of TEST and TRAIN is:\\n')\n",
    "print(accuracy_test)\n",
    "print(accuracy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to do now to get a more reliable score?\n",
    "\n",
    "let's run the whole process of data splitting, training, and predicting,\n",
    "more than once, and get the distribution of the different accuracy scores we get each time.\n",
    "\n",
    "Generating different train and test splits is called cross-validation. This helps us have a\n",
    "more reliable estimation of our model's accuracy. What we did in the previous section is\n",
    "one of many cross-validation strategies called repeated random sub-sampling validation, or\n",
    "Monte Carlo cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.951 [5th percentile: 0.911 & 95th percentile:1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A list to store the score from each iteration\n",
    "accuracy_scores = []\n",
    "\n",
    "for _ in range(100):\n",
    "    # At each iteration we freshly split our data\n",
    "    df_train, df_test = train_test_split(df, test_size=0.3)\n",
    "    x_train = df_train[iris.feature_names]\n",
    "    x_test = df_test[iris.feature_names]\n",
    "    y_train = df_train['target']\n",
    "    y_test = df_test['target']\n",
    "    # We then create a new classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    # And use it for training and prediction\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    # Finally, we append the score to our list\n",
    "    accuracy_scores.append(round(accuracy_score(y_test, y_pred), 3))\n",
    "    \n",
    "# Better convert accuracy_scores from a list into a series\n",
    "# Pandas series provides statistical methods to use later\n",
    "accuracy_scores = pd.Series(accuracy_scores)\n",
    "\n",
    "accuracy_scores.plot(\n",
    "    title='Distribution of classifier accuracy',\n",
    "    kind='box')\n",
    "print('Average Score: {:.3} [5th percentile: {:.3} & 95th percentile:{:.3}]'.format(\n",
    "    accuracy_scores.mean(),\n",
    "    accuracy_scores.quantile(.05),\n",
    "    accuracy_scores.quantile(.95)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShuffleSplit\n",
    "scikit-learn's `ShuffleSplit` module provides us with the functionality to perform [Monte\n",
    "Carlo cross-validation](https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179b). Rather than us splitting the data ourselves, ShuffleSplit gives us\n",
    "lists of indices to use for splitting our data. In the following code, we are going to use the\n",
    "DataFrame's loc() method and the indices we get from ShuffleSplit to randomly split\n",
    "the dataset into 100 training and test pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "# instance shuffle split\n",
    "rs = ShuffleSplit(n_splits = 100, test_size = 0.3)\n",
    "\n",
    "# Now we jave 100 pairs os indices\n",
    "for train_index, test_index in rs.split(df):\n",
    "    x_train = df.loc[train_index, iris.feature_names]\n",
    "    x_test = df.loc[test_index, iris.feature_names]\n",
    "    y_train = df.loc[train_index, 'target']\n",
    "    y_test = df.loc[test_index, 'target']\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    accuracy_scores.append(round(accuracy_score(y_test, y_pred), 3))\n",
    "\n",
    "accuracy_scores = pd.Series(accuracy_scores)\n",
    "    \n",
    "#accuracy_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can simplify the preceding code even further by using scikit-\n",
    "learn's `cross_validate` functionality. This time, we are not event splitting the data into\n",
    "training and test sets ourselves. We will give cross_validate the x and y values for the\n",
    "entire set, and then give it our ShuffleSplit instance for it to use internally to split the\n",
    "data. We also give it the classifier and specify what kind of scoring metric to use. When\n",
    "done, it will give us back a list with the calculated test set scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "dlf = DecisionTreeClassifier()\n",
    "rs = ShuffleSplit(n_splits=100, test_size=0.3)\n",
    "\n",
    "x = df[iris.feature_names]\n",
    "y = df['target']\n",
    "\n",
    "# application of cross validation method passing the estimator (clf), X, y, cross valid generator (cv) \n",
    "# and We also give it the classifier and specify what kind of scoring metric to use. \n",
    "cross_validation_results = cross_validate(clf, x, y, cv=rs, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_time', 'score_time', 'test_score'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.911111\n",
       "1     0.977778\n",
       "2     1.000000\n",
       "3     0.933333\n",
       "4     0.911111\n",
       "        ...   \n",
       "95    0.955556\n",
       "96    0.955556\n",
       "97    0.933333\n",
       "98    0.955556\n",
       "99    0.977778\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores = pd.Series(cross_validation_results['test_score'])\n",
    "accuracy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.942 [5th percentile: 0.889 & 95th percentile:1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_scores.plot(\n",
    "    title='Distribution of classifier accuracy',\n",
    "    kind='box')\n",
    "print('Average Score: {:.3} [5th percentile: {:.3} & 95th percentile:{:.3}]'.format(\n",
    "    accuracy_scores.mean(),\n",
    "    accuracy_scores.quantile(.05),\n",
    "    accuracy_scores.quantile(.95)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation is recommended when dealing with a small dataset\n",
    "since a group of\n",
    "accuracy scores will give us a better understanding of the classifier's performance\n",
    "compared to a single score calculated after a single trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
